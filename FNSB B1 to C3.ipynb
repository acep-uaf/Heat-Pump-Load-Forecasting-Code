{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24f7232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [timestamp, HP_kWh, Total_HP_kWh, variance, percent_difference]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    return df\n",
    "\n",
    "dfb1 = load_and_scale('FNSB_B1.csv', 24293)\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "\n",
    "# Function to merge dataframes and calculate average\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "# Merge and average for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "\n",
    "# Combining averages\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = dfsal.iloc[:, 1:].sum(axis=1) + dffbk.iloc[:, 1:].sum(axis=1) + dfnp.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Merging and calculating variances\n",
    "merged_df = pd.merge(dfb1, dfc3, on='timestamp', suffixes=('_b1', '_c3'))\n",
    "merged_df['variance'] = (merged_df['HP_kWh'] - merged_df['Total_HP_kWh']).abs() # Adjust column names correctly\n",
    "merged_df['percent_difference'] = merged_df['variance'] / merged_df[['HP_kWh', 'Total_HP_kWh']].mean(axis=1) * 100\n",
    "\n",
    "# Sorting and selecting top variances\n",
    "top_variances = merged_df.sort_values(by='variance', ascending=False).head(5)\n",
    "\n",
    "# Display the results\n",
    "print(top_variances[['timestamp', 'HP_kWh', 'Total_HP_kWh', 'variance', 'percent_difference']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0ded2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HP_kWh in dfb1: 6479794627.753269\n",
      "Total HP_kWh in dfc3: 71463865.70687741\n",
      "Variance: 6408330762.0463915\n",
      "Percent Difference: 195.64%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    return df\n",
    "\n",
    "dfb1 = load_and_scale('FNSB_B1.csv', 24293)\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "\n",
    "# Function to merge dataframes\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "\n",
    "# Combining averages\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = dfsal.iloc[:, 1:].sum(axis=1) + dffbk.iloc[:, 1:].sum(axis=1) + dfnp.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Calculate the total HP_kWh for each DataFrame\n",
    "total_HP_kWh_b1 = dfb1['HP_kWh'].sum()\n",
    "total_HP_kWh_c3 = dfc3['Total_HP_kWh'].sum()\n",
    "\n",
    "# Calculate variance and percent difference\n",
    "variance = abs(total_HP_kWh_b1 - total_HP_kWh_c3)\n",
    "percent_difference = (variance / ((total_HP_kWh_b1 + total_HP_kWh_c3) / 2)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total HP_kWh in dfb1: {total_HP_kWh_b1}\")\n",
    "print(f\"Total HP_kWh in dfc3: {total_HP_kWh_c3}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Percent Difference: {percent_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262539b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample raw data from dfb1:\n",
      "    Total_kWh     HP_kWh     Sec_kWh      timestamp\n",
      "0  427.307267  14.431828  412.875440  1/1/2018 0:30\n",
      "1  432.002674  14.992676  417.009998  1/1/2018 1:30\n",
      "2  433.630780  14.431828  419.198952  1/1/2018 2:30\n",
      "3  434.870151  13.978810  420.891340  1/1/2018 3:30\n",
      "4  437.241468  13.978810  423.262657  1/1/2018 4:30\n",
      "Sample raw data from dfsal1:\n",
      "   Total_kWh  HP_kWh   Sec_kWh      timestamp\n",
      "0   3.887217     0.0  3.887217  1/1/2018 0:30\n",
      "1   3.916056     0.0  3.916056  1/1/2018 1:30\n",
      "2   3.964121     0.0  3.964121  1/1/2018 2:30\n",
      "3   4.002573     0.0  4.002573  1/1/2018 3:30\n",
      "4   4.031412     0.0  4.031412  1/1/2018 4:30\n",
      "Sample raw data from dfsal2:\n",
      "   Total_kWh  HP_kWh   Sec_kWh      timestamp\n",
      "0   6.804754     0.0  6.804754  1/1/2018 0:30\n",
      "1   6.854242     0.0  6.854242  1/1/2018 1:30\n",
      "2   6.936720     0.0  6.936720  1/1/2018 2:30\n",
      "3   7.002704     0.0  7.002704  1/1/2018 3:30\n",
      "4   7.052191     0.0  7.052191  1/1/2018 4:30\n",
      "Sample raw data from dfsal3:\n",
      "   Total_kWh  HP_kWh    Sec_kWh      timestamp\n",
      "0  10.053551     0.0  10.053551  1/1/2018 0:30\n",
      "1  10.126031     0.0  10.126031  1/1/2018 1:30\n",
      "2  10.246832     0.0  10.246832  1/1/2018 2:30\n",
      "3  10.343472     0.0  10.343472  1/1/2018 3:30\n",
      "4  10.415952     0.0  10.415952  1/1/2018 4:30\n",
      "Raw Total HP_kWh in raw_dfb1: 266735.05239177\n",
      "Raw Total HP_kWh in raw_dfsal1: 1977.918439734\n",
      "Raw Total HP_kWh in raw_dfsal2: 4152.253288958\n",
      "Raw Total HP_kWh in raw_dfsal3: 6111.15264949\n",
      "Sample scaled data from dfb1:\n",
      "    Total_kWh         HP_kWh     Sec_kWh      timestamp\n",
      "0  427.307267  350592.387887  412.875440  1/1/2018 0:30\n",
      "1  432.002674  364217.071995  417.009998  1/1/2018 1:30\n",
      "2  433.630780  350592.387887  419.198952  1/1/2018 2:30\n",
      "3  434.870151  339587.239104  420.891340  1/1/2018 3:30\n",
      "4  437.241468  339587.239104  423.262657  1/1/2018 4:30\n",
      "Sample scaled data from dfsal1:\n",
      "   Total_kWh  HP_kWh   Sec_kWh      timestamp\n",
      "0   3.887217     0.0  3.887217  1/1/2018 0:30\n",
      "1   3.916056     0.0  3.916056  1/1/2018 1:30\n",
      "2   3.964121     0.0  3.964121  1/1/2018 2:30\n",
      "3   4.002573     0.0  4.002573  1/1/2018 3:30\n",
      "4   4.031412     0.0  4.031412  1/1/2018 4:30\n",
      "Sample scaled data from dfsal2:\n",
      "   Total_kWh  HP_kWh   Sec_kWh      timestamp\n",
      "0   6.804754     0.0  6.804754  1/1/2018 0:30\n",
      "1   6.854242     0.0  6.854242  1/1/2018 1:30\n",
      "2   6.936720     0.0  6.936720  1/1/2018 2:30\n",
      "3   7.002704     0.0  7.002704  1/1/2018 3:30\n",
      "4   7.052191     0.0  7.052191  1/1/2018 4:30\n",
      "Sample scaled data from dfsal3:\n",
      "   Total_kWh  HP_kWh    Sec_kWh      timestamp\n",
      "0  10.053551     0.0  10.053551  1/1/2018 0:30\n",
      "1  10.126031     0.0  10.126031  1/1/2018 1:30\n",
      "2  10.246832     0.0  10.246832  1/1/2018 2:30\n",
      "3  10.343472     0.0  10.343472  1/1/2018 3:30\n",
      "4  10.415952     0.0  10.415952  1/1/2018 4:30\n",
      "Scaled Total HP_kWh in dfb1: 6479794627.753269\n",
      "Scaled Total HP_kWh in dfsal1: 543927.57092685\n",
      "Scaled Total HP_kWh in dfsal2: 759862.351879314\n",
      "Scaled Total HP_kWh in dfsal3: 110000.74769082\n",
      "dfsal shape: (8760, 4)\n",
      "dffbk shape: (8760, 4)\n",
      "dfnp shape: (8760, 4)\n",
      "       timestamp  HP_kWh_1  HP_kWh_2  HP_kWh_3\n",
      "0  1/1/2018 0:30       0.0       0.0       0.0\n",
      "1  1/1/2018 1:30       0.0       0.0       0.0\n",
      "2  1/1/2018 2:30       0.0       0.0       0.0\n",
      "3  1/1/2018 3:30       0.0       0.0       0.0\n",
      "4  1/1/2018 4:30       0.0       0.0       0.0\n",
      "       timestamp      HP_kWh_1  HP_kWh_2  HP_kWh_3\n",
      "0  1/1/2018 0:30  23106.662869    1791.3      21.0\n",
      "1  1/1/2018 1:30  24004.631550    1791.3      21.0\n",
      "2  1/1/2018 2:30  23106.662869    1791.3      21.0\n",
      "3  1/1/2018 3:30  22381.341175    1791.3      21.0\n",
      "4  1/1/2018 4:30  22381.341175    1791.3      21.0\n",
      "       timestamp  HP_kWh_1  HP_kWh_2  HP_kWh_3\n",
      "0  1/1/2018 0:30       0.0       0.0       0.0\n",
      "1  1/1/2018 1:30       0.0       0.0       0.0\n",
      "2  1/1/2018 2:30       0.0       0.0       0.0\n",
      "3  1/1/2018 3:30       0.0       0.0       0.0\n",
      "4  1/1/2018 4:30       0.0       0.0       0.0\n",
      "dfc3 shape: (8760, 2)\n",
      "       timestamp  Total_HP_kWh\n",
      "0  1/1/2018 0:30  24918.962869\n",
      "1  1/1/2018 1:30  25816.931550\n",
      "2  1/1/2018 2:30  24918.962869\n",
      "3  1/1/2018 3:30  24193.641175\n",
      "4  1/1/2018 4:30  24193.641175\n",
      "Total HP_kWh in dfsal: 1413790.670496984\n",
      "Total HP_kWh in dffbk: 43107323.650467925\n",
      "Total HP_kWh in dfnp: 26942751.385912508\n",
      "Total HP_kWh in dfb1: 6479794627.753269\n",
      "Total HP_kWh in dfc3: 71463865.70687741\n",
      "Variance: 6408330762.0463915\n",
      "Percent Difference: 195.64%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data without scaling\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Load and scale data\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    return df\n",
    "\n",
    "# Loading dataframes without scaling\n",
    "raw_dfb1 = load_data('FNSB_B1.csv')\n",
    "raw_dfsal1 = load_data('Salcha_bin1.csv')\n",
    "raw_dfsal2 = load_data('Salcha_bin2.csv')\n",
    "raw_dfsal3 = load_data('Salcha_bin3.csv')\n",
    "raw_dffbk1 = load_data('FBK_bin1.csv')\n",
    "raw_dffbk2 = load_data('FBK_bin2.csv')\n",
    "raw_dffbk3 = load_data('FBK_bin3.csv')\n",
    "raw_dfnp1 = load_data('NP_bin1.csv')\n",
    "raw_dfnp2 = load_data('NP_bin2.csv')\n",
    "raw_dfnp3 = load_data('NP_bin3.csv')\n",
    "\n",
    "# Print some sample rows of raw data\n",
    "print(\"Sample raw data from dfb1:\")\n",
    "print(raw_dfb1.head())\n",
    "print(\"Sample raw data from dfsal1:\")\n",
    "print(raw_dfsal1.head())\n",
    "print(\"Sample raw data from dfsal2:\")\n",
    "print(raw_dfsal2.head())\n",
    "print(\"Sample raw data from dfsal3:\")\n",
    "print(raw_dfsal3.head())\n",
    "\n",
    "# Print sum of raw HP_kWh\n",
    "print(f\"Raw Total HP_kWh in raw_dfb1: {raw_dfb1['HP_kWh'].sum()}\")\n",
    "print(f\"Raw Total HP_kWh in raw_dfsal1: {raw_dfsal1['HP_kWh'].sum()}\")\n",
    "print(f\"Raw Total HP_kWh in raw_dfsal2: {raw_dfsal2['HP_kWh'].sum()}\")\n",
    "print(f\"Raw Total HP_kWh in raw_dfsal3: {raw_dfsal3['HP_kWh'].sum()}\")\n",
    "\n",
    "# Loading dataframes with scaling\n",
    "dfb1 = load_and_scale('FNSB_B1.csv', 24293)\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "\n",
    "# Print some sample rows of scaled data\n",
    "print(\"Sample scaled data from dfb1:\")\n",
    "print(dfb1.head())\n",
    "print(\"Sample scaled data from dfsal1:\")\n",
    "print(dfsal1.head())\n",
    "print(\"Sample scaled data from dfsal2:\")\n",
    "print(dfsal2.head())\n",
    "print(\"Sample scaled data from dfsal3:\")\n",
    "print(dfsal3.head())\n",
    "\n",
    "# Check sum of scaled HP_kWh\n",
    "print(f\"Scaled Total HP_kWh in dfb1: {dfb1['HP_kWh'].sum()}\")\n",
    "print(f\"Scaled Total HP_kWh in dfsal1: {dfsal1['HP_kWh'].sum()}\")\n",
    "print(f\"Scaled Total HP_kWh in dfsal2: {dfsal2['HP_kWh'].sum()}\")\n",
    "print(f\"Scaled Total HP_kWh in dfsal3: {dfsal3['HP_kWh'].sum()}\")\n",
    "\n",
    "# Function to merge dataframes\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merging dataframes for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "\n",
    "# Check the combined dataframes\n",
    "print(f\"dfsal shape: {dfsal.shape}\")\n",
    "print(f\"dffbk shape: {dffbk.shape}\")\n",
    "print(f\"dfnp shape: {dfnp.shape}\")\n",
    "print(dfsal.head())\n",
    "print(dffbk.head())\n",
    "print(dfnp.head())\n",
    "\n",
    "# Combining averages\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = dfsal.iloc[:, 1:].sum(axis=1) + dffbk.iloc[:, 1:].sum(axis=1) + dfnp.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Check the combined dataframe\n",
    "print(f\"dfc3 shape: {dfc3.shape}\")\n",
    "print(dfc3.head())\n",
    "\n",
    "# Check sums of individual dataframes before combining\n",
    "total_HP_kWh_dfsal = dfsal.iloc[:, 1:].sum().sum()\n",
    "total_HP_kWh_dffbk = dffbk.iloc[:, 1:].sum().sum()\n",
    "total_HP_kWh_dfnp = dfnp.iloc[:, 1:].sum().sum()\n",
    "\n",
    "print(f\"Total HP_kWh in dfsal: {total_HP_kWh_dfsal}\")\n",
    "print(f\"Total HP_kWh in dffbk: {total_HP_kWh_dffbk}\")\n",
    "print(f\"Total HP_kWh in dfnp: {total_HP_kWh_dfnp}\")\n",
    "\n",
    "# Calculate the total HP_kWh for each DataFrame\n",
    "total_HP_kWh_b1 = dfb1['HP_kWh'].sum()\n",
    "total_HP_kWh_c3 = dfc3['Total_HP_kWh'].sum()\n",
    "\n",
    "# Calculate variance and percent difference\n",
    "variance = abs(total_HP_kWh_b1 - total_HP_kWh_c3)\n",
    "percent_difference = (variance / ((total_HP_kWh_b1 + total_HP_kWh_c3) / 2)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total HP_kWh in dfb1: {total_HP_kWh_b1}\")\n",
    "print(f\"Total HP_kWh in dfc3: {total_HP_kWh_c3}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Percent Difference: {percent_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6979da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp        HP_kWh   Total_HP_kWh      variance  \\\n",
      "191  2018-01-08 23:30:00  1.776661e+06  269439.532046  1.507222e+06   \n",
      "7751 2018-11-19 23:30:00  1.755723e+06  266703.455851  1.489020e+06   \n",
      "1709 2018-03-13 05:30:00  1.800526e+06  273602.386172  1.526923e+06   \n",
      "1711 2018-03-13 07:30:00  1.800526e+06  273602.386172  1.526923e+06   \n",
      "2140 2018-03-31 04:30:00  2.618136e+06  398036.392951  2.220100e+06   \n",
      "\n",
      "      percent_difference  \n",
      "191           147.326242  \n",
      "7751          147.250809  \n",
      "1709          147.235204  \n",
      "1711          147.235204  \n",
      "2140          147.213053  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "dfb1 = load_and_scale('FNSB_B1.csv', 24293)\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)\n",
    "    return df_merged\n",
    "\n",
    "# Merge and average for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "\n",
    "# Combining averages\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = dfsal.filter(like='HP_kWh').sum(axis=1) + dffbk.filter(like='HP_kWh').sum(axis=1) + dfnp.filter(like='HP_kWh').sum(axis=1)\n",
    "\n",
    "# Merging and calculating variances\n",
    "merged_df = pd.merge(dfb1, dfc3, on='timestamp', suffixes=('_b1', '_c3'))\n",
    "merged_df['variance'] = (merged_df['HP_kWh'] - merged_df['Total_HP_kWh']).abs()\n",
    "merged_df['percent_difference'] = merged_df['variance'] / merged_df[['HP_kWh', 'Total_HP_kWh']].mean(axis=1) * 100\n",
    "\n",
    "# Sorting and selecting top percent differences\n",
    "top_percent_differences = merged_df.sort_values(by='percent_difference', ascending=False).head(5)\n",
    "\n",
    "# Display the results\n",
    "print(top_percent_differences[['timestamp', 'HP_kWh', 'Total_HP_kWh', 'variance', 'percent_difference']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "476d61f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HP_kWh in dfb1: 6479794627.753269\n",
      "Total HP_kWh in dfc3: 1945444370.6714609\n",
      "Overall Variance: 4534350257.081808\n",
      "Overall Percent Difference: 107.64%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "dfb1 = load_and_scale('FNSB_B1.csv', 24293)\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "\n",
    "# Function to merge dataframes\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "\n",
    "# Combining averages\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = dfsal.filter(like='HP_kWh').sum(axis=1) + dffbk.filter(like='HP_kWh').sum(axis=1) + dfnp.filter(like='HP_kWh').sum(axis=1)\n",
    "\n",
    "# Merging and calculating variances\n",
    "merged_df = pd.merge(dfb1, dfc3, on='timestamp', suffixes=('_b1', '_c3'))\n",
    "merged_df['variance'] = (merged_df['HP_kWh'] - merged_df['Total_HP_kWh']).abs()\n",
    "merged_df['percent_difference'] = merged_df['variance'] / merged_df[['HP_kWh', 'Total_HP_kWh']].mean(axis=1) * 100\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the total HP_kWh for each DataFrame\n",
    "total_HP_kWh_b1 = dfb1['HP_kWh'].sum()\n",
    "total_HP_kWh_c3 = dfc3['Total_HP_kWh'].sum()\n",
    "\n",
    "# Calculate overall variance and percent difference\n",
    "overall_variance = abs(total_HP_kWh_b1 - total_HP_kWh_c3)\n",
    "overall_percent_difference = (overall_variance / ((total_HP_kWh_b1 + total_HP_kWh_c3) / 2)) * 100\n",
    "\n",
    "# Display the overall results\n",
    "print(f\"Total HP_kWh in dfb1: {total_HP_kWh_b1}\")\n",
    "print(f\"Total HP_kWh in dfc3: {total_HP_kWh_c3}\")\n",
    "print(f\"Overall Variance: {overall_variance}\")\n",
    "print(f\"Overall Percent Difference: {overall_percent_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6d588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
