{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a24f7232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp  Total_HP_kWh_b1  Total_HP_kWh_c3     variance  \\\n",
      "5101 2018-08-01 13:30:00      7912.623331      1311.913887  6600.709444   \n",
      "5076 2018-07-31 12:30:00      7912.623331      1311.913887  6600.709444   \n",
      "5104 2018-08-01 16:30:00      7912.623331      1311.913887  6600.709444   \n",
      "5079 2018-07-31 15:30:00      7912.623331      1311.913887  6600.709444   \n",
      "5077 2018-07-31 13:30:00      7912.623331      1311.913887  6600.709444   \n",
      "\n",
      "      percent_difference  \n",
      "5101          143.111991  \n",
      "5076          143.111991  \n",
      "5104          143.111991  \n",
      "5079          143.111991  \n",
      "5077          143.111991  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    dffnsb = load_and_scale('FNSB_B1.csv', 24293)\n",
    "    dfkpb = load_and_scale('KPB_B1.csv', 9730)\n",
    "    dfmatsu = load_and_scale('Mat_Su_B1.csv', 31715)\n",
    "    dfanc_b1 = load_and_scale('ANC_B1.csv', 14654)\n",
    "    dfden_b1 = load_and_scale('Denali_B1.csv', 2403)\n",
    "\n",
    "    dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "    dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "    dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "    dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "    dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "    dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "    dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "    dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "    dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "    dfken1 = load_and_scale('Kenai_bin1.csv', 3458)\n",
    "    dfken2 = load_and_scale('Kenai_bin2.csv', 603)\n",
    "    dfken3 = load_and_scale('Kenai_bin3.csv', 18)\n",
    "    dfwas1 = load_and_scale('Wasilla_bin1.csv', 21322)\n",
    "    dfwas2 = load_and_scale('Wasilla_bin2.csv', 16)\n",
    "    dfwas3 = load_and_scale('Wasilla_bin3.csv', 2)\n",
    "    dfnik1 = load_and_scale('Nikiski_bin1.csv', 386)\n",
    "    dfnik2 = load_and_scale('Nikiski_bin2.csv', 156)\n",
    "    dfnik3 = load_and_scale('Nikiski_bin3.csv', 12)\n",
    "    dfsold1 = load_and_scale('Soldotna_bin1.csv', 4653)\n",
    "    dfsold2 = load_and_scale('Soldotna_bin2.csv', 437)\n",
    "    dfsold3 = load_and_scale('Soldotna_bin3.csv', 9)\n",
    "    dfpalm1 = load_and_scale('Palmer_bin1.csv', 9656)\n",
    "    dfpalm2 = load_and_scale('Palmer_bin2.csv', 115)\n",
    "    dfpalm3 = load_and_scale('Palmer_bin3.csv', 7)\n",
    "    dfhoust1 = load_and_scale('Houston_bin1.csv', 503)\n",
    "    dfhoust2 = load_and_scale('Houston_bin2.csv', 87)\n",
    "    dfhoust3 = load_and_scale('Houston_bin3.csv', 7)\n",
    "    dfanc_bin1 = load_and_scale('ANC_bin1.csv', 14134)\n",
    "    dfanc_bin2 = load_and_scale('ANC_bin2.csv', 472)\n",
    "    dfanc_bin3 = load_and_scale('ANC_bin3.csv', 48)\n",
    "    dfden_bin1 = load_and_scale('Denali_bin1.csv', 2401)\n",
    "    dfden_bin2 = load_and_scale('Denali_bin2.csv', 2)\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "    raise\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "dfken = merge_dataframes([dfken1, dfken2, dfken3])\n",
    "dfwas = merge_dataframes([dfwas1, dfwas2, dfwas3])\n",
    "dfpalm = merge_dataframes([dfpalm1, dfpalm2, dfpalm3])\n",
    "dfsold = merge_dataframes([dfsold1, dfsold2, dfsold3])\n",
    "dfhoust = merge_dataframes([dfhoust1, dfhoust2, dfhoust3])\n",
    "dfnik = merge_dataframes([dfnik1, dfnik2, dfnik3])\n",
    "dfanc = merge_dataframes([dfanc_bin1, dfanc_bin2, dfanc_bin3])\n",
    "dfden = merge_dataframes([dfden_bin1, dfden_bin2])\n",
    "\n",
    "# Combining dfb1\n",
    "dfb1 = pd.DataFrame()\n",
    "dfb1['timestamp'] = dffnsb['timestamp']\n",
    "dfb1['Total_HP_kWh'] = (\n",
    "    dffnsb['HP_kWh'] +\n",
    "    dfkpb['HP_kWh'] +\n",
    "    dfmatsu['HP_kWh'] +\n",
    "    dfanc_b1['HP_kWh'] +\n",
    "    dfden_b1['HP_kWh']\n",
    ")\n",
    "\n",
    "# Combining averages for dfc3\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = (\n",
    "    dfsal.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dffbk.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnp.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfken.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfwas.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfpalm.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnik.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfhoust.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfsold.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfanc.filter(like='HP_kWh').sum(axis=1) + \n",
    "    dfden.filter(like='HP_kWh').sum(axis=1)\n",
    ")\n",
    "\n",
    "# Merging and calculating variances\n",
    "merged_df = pd.merge(dfb1, dfc3, on='timestamp', suffixes=('_b1', '_c3'))\n",
    "merged_df['variance'] = (merged_df['Total_HP_kWh_b1'] - merged_df['Total_HP_kWh_c3']).abs()\n",
    "merged_df['percent_difference'] = merged_df['variance'] / merged_df[['Total_HP_kWh_b1', 'Total_HP_kWh_c3']].mean(axis=1) * 100\n",
    "\n",
    "# Sorting and selecting top percent differences\n",
    "top_percent_differences = merged_df.sort_values(by='percent_difference', ascending=False).head(5)\n",
    "\n",
    "# Display the results\n",
    "print(top_percent_differences[['timestamp', 'Total_HP_kWh_b1', 'Total_HP_kWh_c3', 'variance', 'percent_difference']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f0ded2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HP_kWh in dfb1: 33702264189.74153\n",
      "Total HP_kWh in dfc3: 13614334117.365341\n",
      "Variance: 20087930072.37619\n",
      "Percent Difference: 84.91%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "dffnsb = load_and_scale('FNSB_B1.csv', 24293)\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "dfken1 = load_and_scale('Kenai_bin1.csv', 3458)\n",
    "dfken2 = load_and_scale('Kenai_bin2.csv', 603)\n",
    "dfken3 = load_and_scale('Kenai_bin3.csv', 18)\n",
    "dfwas1 = load_and_scale('Wasilla_bin1.csv', 21322)\n",
    "dfwas2 = load_and_scale('Wasilla_bin2.csv', 16)\n",
    "dfwas3 = load_and_scale('Wasilla_bin3.csv', 2)\n",
    "dfnik1 = load_and_scale('Nikiski_bin1.csv', 386)\n",
    "dfnik2 = load_and_scale('Nikiski_bin1.csv', 156)\n",
    "dfnik3 = load_and_scale('Nikiski_bin1.csv', 12)\n",
    "dfsold1 = load_and_scale('Soldotna_bin1.csv', 4653)\n",
    "dfsold2 = load_and_scale('Soldotna_bin2.csv', 437)\n",
    "dfsold3 = load_and_scale('Soldotna_bin3.csv', 9)\n",
    "dfpalm1 = load_and_scale('Palmer_bin1.csv', 9656)\n",
    "dfpalm2 = load_and_scale('Palmer_bin2.csv', 115)\n",
    "dfpalm3 = load_and_scale('Palmer_bin3.csv', 7)\n",
    "dfhoust1 = load_and_scale('Houston_bin1.csv', 503)\n",
    "dfhoust2 = load_and_scale('Houston_bin2.csv', 87)\n",
    "dfhoust3 = load_and_scale('Houston_bin3.csv', 7)\n",
    "dfanc_bin1 = load_and_scale('ANC_bin1.csv', 14134)\n",
    "dfanc_bin2 = load_and_scale('ANC_bin2.csv', 472)\n",
    "dfanc_bin3 = load_and_scale('ANC_bin3.csv', 48)\n",
    "dfden_bin1 = load_and_scale('Denali_bin1.csv', 2401)\n",
    "dfden_bin2 = load_and_scale('Denali_bin2.csv', 2)\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "dfken = merge_dataframes([dfken1, dfken2, dfken3])\n",
    "dfwas = merge_dataframes([dfwas1, dfwas2, dfwas3])\n",
    "dfpalm = merge_dataframes([dfpalm1, dfpalm2, dfpalm3])\n",
    "dfsold = merge_dataframes([dfsold1, dfsold2, dfsold3])\n",
    "dfhoust = merge_dataframes([dfhoust1, dfhoust2, dfhoust3])\n",
    "dfnik = merge_dataframes([dfnik1, dfnik2, dfnik3])\n",
    "dfanc = merge_dataframes([dfanc_bin1, dfanc_bin2, dfanc_bin3])\n",
    "dfden = merge_dataframes([dfden_bin1, dfden_bin2])\n",
    "\n",
    "# Combining dfb1\n",
    "dfb1 = pd.DataFrame()\n",
    "dfb1['timestamp'] = dffnsb['timestamp']\n",
    "dfb1['Total_HP_kWh'] = (\n",
    "    dffnsb['HP_kWh'] +\n",
    "    dfkpb['HP_kWh'] +\n",
    "    dfmatsu['HP_kWh'] +\n",
    "    dfanc_b1['HP_kWh'] +\n",
    "    dfden_b1['HP_kWh']\n",
    ")\n",
    "\n",
    "# Combining averages for dfc3\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = (\n",
    "    dfsal.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dffbk.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnp.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfken.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfwas.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfpalm.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnik.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfhoust.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfsold.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfanc.filter(like='HP_kWh').sum(axis=1) + \n",
    "    dfden.filter(like='HP_kWh').sum(axis=1)\n",
    ")\n",
    "\n",
    "# Calculate total HP_kWh for each DataFrame\n",
    "total_HP_kWh_b1 = dfb1['Total_HP_kWh'].sum()\n",
    "total_HP_kWh_c3 = dfc3['Total_HP_kWh'].sum()\n",
    "\n",
    "# Calculate the absolute variance and percent difference\n",
    "variance = abs(total_HP_kWh_b1 - total_HP_kWh_c3)\n",
    "percent_difference = (variance / ((total_HP_kWh_b1 + total_HP_kWh_c3) / 2)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total HP_kWh in dfb1: {total_HP_kWh_b1}\")\n",
    "print(f\"Total HP_kWh in dfc3: {total_HP_kWh_c3}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Percent Difference: {percent_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd0cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
