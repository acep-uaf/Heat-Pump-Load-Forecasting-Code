{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5702e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in merged_df: Index(['timestamp', 'HP_kWh_c1', 'Total_HP_kWh'], dtype='object')\n",
      "                timestamp      HP_kWh_c1   Total_HP_kWh       variance  \\\n",
      "3729  2018-06-05 09:30:00  393375.445665  219008.532297  174366.913368   \n",
      "3717  2018-06-04 21:30:00  326844.457914  182938.319321  143906.138594   \n",
      "5823  2018-08-31 15:30:00  492196.394562  276565.285451  215631.109111   \n",
      "3728  2018-06-05 08:30:00  457894.873501  257814.650840  200080.222661   \n",
      "3730  2018-06-05 10:30:00  204164.159131  114954.363371   89209.795760   \n",
      "\n",
      "      percent_difference  \n",
      "3729           56.946922  \n",
      "3717           56.457827  \n",
      "5823           56.098298  \n",
      "3728           55.911013  \n",
      "3730           55.910133  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    return df\n",
    "\n",
    "# C3 dataframes\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "dfken1 = load_and_scale('Kenai_bin1.csv', 3458)\n",
    "dfken2 = load_and_scale('Kenai_bin2.csv', 603)\n",
    "dfken3 = load_and_scale('Kenai_bin3.csv', 18)\n",
    "dfwas1 = load_and_scale('Wasilla_bin1.csv', 21322)\n",
    "dfwas2 = load_and_scale('Wasilla_bin2.csv', 16)\n",
    "dfwas3 = load_and_scale('Wasilla_bin3.csv', 2)\n",
    "dfnik1 = load_and_scale('Nikiski_bin1.csv', 386)\n",
    "dfnik2 = load_and_scale('Nikiski_bin2.csv', 156)\n",
    "dfnik3 = load_and_scale('Nikiski_bin3.csv', 12)\n",
    "dfsold1 = load_and_scale('Soldotna_bin1.csv', 4653)\n",
    "dfsold2 = load_and_scale('Soldotna_bin2.csv', 437)\n",
    "dfsold3 = load_and_scale('Soldotna_bin3.csv', 9)\n",
    "dfpalm1 = load_and_scale('Palmer_bin1.csv', 9656)\n",
    "dfpalm2 = load_and_scale('Palmer_bin2.csv', 115)\n",
    "dfpalm3 = load_and_scale('Palmer_bin3.csv', 7)\n",
    "dfhoust1 = load_and_scale('Houston_bin1.csv', 503)\n",
    "dfhoust2 = load_and_scale('Houston_bin2.csv', 87)\n",
    "dfhoust3 = load_and_scale('Houston_bin3.csv', 7)\n",
    "dfanc_bin1 = load_and_scale('ANC_bin1.csv', 14134)\n",
    "dfanc_bin2 = load_and_scale('ANC_bin2.csv', 472)\n",
    "dfanc_bin3 = load_and_scale('ANC_bin3.csv', 48)\n",
    "dfden_bin1 = load_and_scale('Denali_bin1.csv', 2401)\n",
    "dfden_bin2 = load_and_scale('Denali_bin2.csv', 2)\n",
    "\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge dataframes for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "dfken = merge_dataframes([dfken1, dfken2, dfken3])\n",
    "dfwas = merge_dataframes([dfwas1, dfwas2, dfwas3])\n",
    "dfpalm = merge_dataframes([dfpalm1, dfpalm2, dfpalm3])\n",
    "dfsold = merge_dataframes([dfsold1, dfsold2, dfsold3])\n",
    "dfhoust = merge_dataframes([dfhoust1, dfhoust2, dfhoust3])\n",
    "dfnik = merge_dataframes([dfnik1, dfnik2, dfnik3])\n",
    "dfanc = merge_dataframes([dfanc_bin1, dfanc_bin2, dfanc_bin3])\n",
    "dfden = merge_dataframes([dfden_bin1, dfden_bin2])\n",
    "\n",
    "# Combining HP_kWh columns\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = (\n",
    "    dfsal.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dffbk.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnp.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfken.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfwas.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfpalm.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnik.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfhoust.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfsold.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfanc.filter(like='HP_kWh').sum(axis=1) + \n",
    "    dfden.filter(like='HP_kWh').sum(axis=1)\n",
    ")\n",
    "\n",
    "df_salcha = pd.read_csv('Salcha_C1.csv')\n",
    "df_fbx = pd.read_csv('Fairbanks_C1.csv')\n",
    "df_np = pd.read_csv('North Pole_C1.csv')\n",
    "df_ken = pd.read_csv('Kenai_C1.csv')\n",
    "df_was = pd.read_csv('Wasilla_C1.csv')\n",
    "df_nik = pd.read_csv('Nikiski_C1.csv')\n",
    "df_palm = pd.read_csv('Palmer_C1.csv')\n",
    "df_houst = pd.read_csv('Houston_C1.csv')\n",
    "df_sol = pd.read_csv('Soldotna_C1.csv')\n",
    "df_anc = pd.read_csv('ANC_B1.csv')\n",
    "df_den = pd.read_csv('Denali_B1.csv')\n",
    "\n",
    "df_salcha['HP_kWh'] *= 476\n",
    "df_fbx['HP_kWh'] *= 16703\n",
    "df_np['HP_kWh'] *= 7114\n",
    "df_ken ['HP_kWh'] *= 4077\n",
    "df_was ['HP_kWh'] *= 21340\n",
    "df_nik ['HP_kWh'] *= 554\n",
    "df_palm ['HP_kWh'] *= 9778\n",
    "df_houst ['HP_kWh'] *= 597\n",
    "df_sol ['HP_kWh'] *= 5099\n",
    "df_anc ['HP_kWh'] *= 14654\n",
    "df_den ['HP_kWh'] *= 2403\n",
    "\n",
    "\n",
    "df_C1 = pd.DataFrame()\n",
    "df_C1['timestamp'] = df_salcha['timestamp']  # Assuming timestamp is aligned and exists in all datasets\n",
    "df_C1['HP_kWh_c1'] = (df_salcha['HP_kWh'] + df_fbx['HP_kWh'] + df_np['HP_kWh'] + \n",
    "                      df_ken['HP_kWh'] + df_nik['HP_kWh'] + df_sol['HP_kWh'] + \n",
    "                      df_palm['HP_kWh'] + df_houst['HP_kWh'] + df_was['HP_kWh'] + df_anc['HP_kWh'] + df_den['HP_kWh'])\n",
    "\n",
    "# Merging and calculating variances\n",
    "merged_df = pd.merge(df_C1, dfc3, on='timestamp', suffixes=('_c1', '_c3'))\n",
    "\n",
    "# Check columns to ensure correct names\n",
    "print(\"Columns in merged_df:\", merged_df.columns)\n",
    "\n",
    "# Calculating variances and percent differences\n",
    "merged_df['variance'] = (merged_df['HP_kWh_c1'] - merged_df['Total_HP_kWh']).abs()\n",
    "merged_df['percent_difference'] = merged_df['variance'] / merged_df[['HP_kWh_c1', 'Total_HP_kWh']].mean(axis=1) * 100\n",
    "\n",
    "# Sorting and selecting top variances\n",
    "top_variances = merged_df.sort_values(by='percent_difference', ascending=False).head(5)\n",
    "\n",
    "# Display the results\n",
    "print(top_variances[['timestamp', 'HP_kWh_c1', 'Total_HP_kWh', 'variance', 'percent_difference']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e605f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HP_kWh in C1: 14344500283.49129\n",
      "Total HP_kWh in C3: 13633021149.963104\n",
      "Variance: 711479133.5281849\n",
      "Percent Difference: 5.09%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    return df\n",
    "\n",
    "# Load and scale data for all bins\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "dfken1 = load_and_scale('Kenai_bin1.csv', 3458)\n",
    "dfken2 = load_and_scale('Kenai_bin2.csv', 603)\n",
    "dfken3 = load_and_scale('Kenai_bin3.csv', 18)\n",
    "dfwas1 = load_and_scale('Wasilla_bin1.csv', 21322)\n",
    "dfwas2 = load_and_scale('Wasilla_bin2.csv', 16)\n",
    "dfwas3 = load_and_scale('Wasilla_bin3.csv', 2)\n",
    "dfnik1 = load_and_scale('Nikiski_bin1.csv', 386)\n",
    "dfnik2 = load_and_scale('Nikiski_bin2.csv', 156)\n",
    "dfnik3 = load_and_scale('Nikiski_bin3.csv', 12)\n",
    "dfsold1 = load_and_scale('Soldotna_bin1.csv', 4653)\n",
    "dfsold2 = load_and_scale('Soldotna_bin2.csv', 437)\n",
    "dfsold3 = load_and_scale('Soldotna_bin3.csv', 9)\n",
    "dfpalm1 = load_and_scale('Palmer_bin1.csv', 9656)\n",
    "dfpalm2 = load_and_scale('Palmer_bin2.csv', 115)\n",
    "dfpalm3 = load_and_scale('Palmer_bin3.csv', 7)\n",
    "dfhoust1 = load_and_scale('Houston_bin1.csv', 503)\n",
    "dfhoust2 = load_and_scale('Houston_bin2.csv', 87)\n",
    "dfhoust3 = load_and_scale('Houston_bin3.csv', 7)\n",
    "dfanc_bin1 = load_and_scale('ANC_bin1.csv', 14134)\n",
    "dfanc_bin2 = load_and_scale('ANC_bin2.csv', 472)\n",
    "dfanc_bin3 = load_and_scale('ANC_bin3.csv', 48)\n",
    "dfden_bin1 = load_and_scale('Denali_bin1.csv', 2401)\n",
    "dfden_bin2 = load_and_scale('Denali_bin2.csv', 2)\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge dataframes for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "dfken = merge_dataframes([dfken1, dfken2, dfken3])\n",
    "dfwas = merge_dataframes([dfwas1, dfwas2, dfwas3])\n",
    "dfpalm = merge_dataframes([dfpalm1, dfpalm2, dfpalm3])\n",
    "dfsold = merge_dataframes([dfsold1, dfsold2, dfsold3])\n",
    "dfhoust = merge_dataframes([dfhoust1, dfhoust2, dfhoust3])\n",
    "dfnik = merge_dataframes([dfnik1, dfnik2, dfnik3])\n",
    "dfanc = merge_dataframes([dfanc_bin1, dfanc_bin2, dfanc_bin3])\n",
    "dfden = merge_dataframes([dfden_bin1, dfden_bin2])\n",
    "\n",
    "# Combining HP_kWh columns\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = (\n",
    "    dfsal.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dffbk.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnp.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfken.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfwas.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfpalm.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnik.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfhoust.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfsold.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfanc.filter(like='HP_kWh').sum(axis=1) + \n",
    "    dfden.filter(like='HP_kWh').sum(axis=1)\n",
    ")\n",
    "\n",
    "df_salcha = pd.read_csv('Salcha_C1.csv')\n",
    "df_fbx = pd.read_csv('Fairbanks_C1.csv')\n",
    "df_np = pd.read_csv('North Pole_C1.csv')\n",
    "df_ken = pd.read_csv('Kenai_C1.csv')\n",
    "df_was = pd.read_csv('Wasilla_C1.csv')\n",
    "df_nik = pd.read_csv('Nikiski_C1.csv')\n",
    "df_palm = pd.read_csv('Palmer_C1.csv')\n",
    "df_houst = pd.read_csv('Houston_C1.csv')\n",
    "df_sol = pd.read_csv('Soldotna_C1.csv')\n",
    "df_anc = pd.read_csv('ANC_B1.csv')\n",
    "df_den = pd.read_csv('Denali_B1.csv')\n",
    "\n",
    "\n",
    "df_salcha['HP_kWh'] *= 476\n",
    "df_fbx['HP_kWh'] *= 16703\n",
    "df_np['HP_kWh'] *= 7114\n",
    "df_ken ['HP_kWh'] *= 4077\n",
    "df_was ['HP_kWh'] *= 21340\n",
    "df_nik ['HP_kWh'] *= 554\n",
    "df_palm ['HP_kWh'] *= 9778\n",
    "df_houst ['HP_kWh'] *= 597\n",
    "df_sol ['HP_kWh'] *= 5099\n",
    "df_anc ['HP_kWh'] *= 14654\n",
    "df_den ['HP_kWh'] *= 2403\n",
    "\n",
    "df_C1 = pd.DataFrame()\n",
    "df_C1['timestamp'] = df_salcha['timestamp']  # Assuming timestamp is aligned and exists in all datasets\n",
    "df_C1['HP_kWh_c1'] = (df_salcha['HP_kWh'] + df_fbx['HP_kWh'] + df_np['HP_kWh'] + \n",
    "                      df_ken['HP_kWh'] + df_nik['HP_kWh'] + df_sol['HP_kWh'] + \n",
    "                      df_palm['HP_kWh'] + df_houst['HP_kWh'] + df_was['HP_kWh'] + df_anc['HP_kWh'] + df_den['HP_kWh'])\n",
    "\n",
    "total_HP_kWh_c1 = df_C1['HP_kWh_c1'].sum()\n",
    "total_HP_kWh_c3 = dfc3['Total_HP_kWh'].sum()\n",
    "\n",
    "variance = abs(total_HP_kWh_c1 - total_HP_kWh_c3)\n",
    "percent_difference = (variance / ((total_HP_kWh_c1 + total_HP_kWh_c3) / 2)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total HP_kWh in C1: {total_HP_kWh_c1}\")\n",
    "print(f\"Total HP_kWh in C3: {total_HP_kWh_c3}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Percent Difference: {percent_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993bc9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
