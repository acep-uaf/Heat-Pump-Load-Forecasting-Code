{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5702e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp      HP_kWh_c1   Total_HP_kWh      variance  \\\n",
      "192  2018-01-09 00:30:00  141450.515759  130282.390043  11168.125716   \n",
      "193  2018-01-09 01:30:00  141450.515759  130282.390043  11168.125716   \n",
      "215  2018-01-09 23:30:00  138894.140726  128152.693408  10741.447318   \n",
      "194  2018-01-09 02:30:00  138005.317836  127451.861273  10553.456563   \n",
      "556  2018-01-24 04:30:00  274635.376527  253819.338002  20816.038525   \n",
      "\n",
      "     percent_difference  \n",
      "192            8.219929  \n",
      "193            8.219929  \n",
      "215            8.044617  \n",
      "194            7.951156  \n",
      "556            7.878078  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    return df\n",
    "\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge dataframes for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "\n",
    "# Combining HP_kWh columns\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = dfsal.iloc[:, 1:].sum(axis=1) + dffbk.iloc[:, 1:].sum(axis=1) + dfnp.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "df_salcha = pd.read_csv('Salcha_C1.csv')\n",
    "df_fbx = pd.read_csv('Fairbanks_C1.csv')\n",
    "df_np = pd.read_csv('North Pole_C1.csv')\n",
    "\n",
    "df_salcha['HP_kWh'] *= 476\n",
    "df_fbx['HP_kWh'] *= 16703\n",
    "df_np['HP_kWh'] *= 7114\n",
    "\n",
    "df_C1 = pd.DataFrame()\n",
    "df_C1['timestamp'] = df_salcha['timestamp']  # Assuming timestamp is aligned and exists in all datasets\n",
    "df_C1['HP_kWh_c1'] = df_salcha['HP_kWh'] + df_fbx['HP_kWh'] + df_np['HP_kWh']\n",
    "\n",
    "# Merging and calculating variances\n",
    "merged_df = pd.merge(df_C1, dfc3, on='timestamp', suffixes=('_c1', '_c3'))\n",
    "merged_df['variance'] = (merged_df['HP_kWh_c1'] - merged_df['Total_HP_kWh']).abs() # Adjust column names correctly\n",
    "merged_df['percent_difference'] = merged_df['variance'] / merged_df[['HP_kWh_c1', 'Total_HP_kWh']].mean(axis=1) * 100\n",
    "\n",
    "# Sorting and selecting top variances\n",
    "top_variances = merged_df.sort_values(by='percent_difference', ascending=False).head(5)\n",
    "\n",
    "# Display the results\n",
    "print(top_variances[['timestamp', 'HP_kWh_c1', 'Total_HP_kWh', 'variance', 'percent_difference']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e605f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HP_kWh in C1: 1972762933.4505243\n",
      "Total HP_kWh in C3: 1945444370.6714609\n",
      "Variance: 27318562.779063463\n",
      "Percent Difference: 1.39%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    return df\n",
    "\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Merge dataframes for each set\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "\n",
    "# Combining HP_kWh columns\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = dfsal.iloc[:, 1:].sum(axis=1) + dffbk.iloc[:, 1:].sum(axis=1) + dfnp.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "df_salcha = pd.read_csv('Salcha_C1.csv')\n",
    "df_fbx = pd.read_csv('Fairbanks_C1.csv')\n",
    "df_np = pd.read_csv('North Pole_C1.csv')\n",
    "\n",
    "df_salcha['HP_kWh'] *= 476\n",
    "df_fbx['HP_kWh'] *= 16703\n",
    "df_np['HP_kWh'] *= 7114\n",
    "\n",
    "df_C1 = pd.DataFrame()\n",
    "df_C1['timestamp'] = df_salcha['timestamp']  # Assuming timestamp is aligned and exists in all datasets\n",
    "df_C1['HP_kWh'] = df_salcha['HP_kWh'] + df_fbx['HP_kWh'] + df_np['HP_kWh']\n",
    "\n",
    "total_HP_kWh_c1 = df_C1['HP_kWh'].sum()\n",
    "total_HP_kWh_c3 = dfc3['Total_HP_kWh'].sum()\n",
    "\n",
    "variance = abs(total_HP_kWh_c1 - total_HP_kWh_c3)\n",
    "percent_difference = (variance / ((total_HP_kWh_c1 + total_HP_kWh_c3) / 2)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total HP_kWh in C1: {total_HP_kWh_c1}\")\n",
    "print(f\"Total HP_kWh in C3: {total_HP_kWh_c3}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Percent Difference: {percent_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993bc9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
