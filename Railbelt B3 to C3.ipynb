{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e1802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 percent differences:\n",
      "               timestamp  Total_HP_kWh_b3  Total_HP_kWh      variance  \\\n",
      "3639 2018-06-01 15:30:00     12552.155217   2080.889858  10471.265360   \n",
      "3640 2018-06-01 16:30:00     32786.078230   5435.259245  27350.818984   \n",
      "5103 2018-08-01 15:30:00     32786.078230   5435.259245  27350.818984   \n",
      "3641 2018-06-01 17:30:00     32786.078230   5435.259245  27350.818984   \n",
      "5102 2018-08-01 14:30:00     32786.078230   5435.259245  27350.818984   \n",
      "\n",
      "      percent_difference  \n",
      "3639          143.118063  \n",
      "3640          143.118063  \n",
      "5103          143.118063  \n",
      "3641          143.118063  \n",
      "5102          143.118063  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "dffnsbbin1 = load_and_scale('FNSB_Bin1.csv', 23016)\n",
    "dffnsbbin2 = load_and_scale('FNSB_Bin2.csv', 1263)\n",
    "dffnsbbin3 = load_and_scale('FNSB_Bin3.csv', 14)\n",
    "dfmatbin1 = load_and_scale('Mat_Su_Bin1.csv', 31691)\n",
    "dfmatbin2 = load_and_scale('Mat_Su_Bin2.csv', 22)\n",
    "dfmatbin3 = load_and_scale('Mat_Su_Bin3.csv', 2)\n",
    "dfkenbin1 = load_and_scale('KPB_Bin1.csv', 3458)\n",
    "dfkenbin2 = load_and_scale('KPB_Bin2.csv', 603)\n",
    "dfkenbin3 = load_and_scale('KPB_Bin3.csv', 18)\n",
    "dfancbin1 = load_and_scale('ANC_Bin1.csv', 14134)\n",
    "dfancbin2 = load_and_scale('ANC_Bin2.csv', 472)\n",
    "dfancbin3 = load_and_scale('ANC_Bin3.csv', 48)\n",
    "dfdenbin1 = load_and_scale('Denali_Bin1.csv', 2401)\n",
    "dfdenbin2 = load_and_scale('Denali_Bin2.csv', 2)\n",
    "\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "dfken1 = load_and_scale('Kenai_bin1.csv', 3458)\n",
    "dfken2 = load_and_scale('Kenai_bin2.csv', 603)\n",
    "dfken3 = load_and_scale('Kenai_bin3.csv', 18)\n",
    "dfwas1 = load_and_scale('Wasilla_bin1.csv', 21322)\n",
    "dfwas2 = load_and_scale('Wasilla_bin2.csv', 16)\n",
    "dfwas3 = load_and_scale('Wasilla_bin3.csv', 2)\n",
    "dfnik1 = load_and_scale('Nikiski_bin1.csv', 386)\n",
    "dfnik2 = load_and_scale('Nikiski_bin2.csv', 156)\n",
    "dfnik3 = load_and_scale('Nikiski_bin3.csv', 12)\n",
    "dfsold1 = load_and_scale('Soldotna_bin1.csv', 4653)\n",
    "dfsold2 = load_and_scale('Soldotna_bin2.csv', 437)\n",
    "dfsold3 = load_and_scale('Soldotna_bin3.csv', 9)\n",
    "dfpalm1 = load_and_scale('Palmer_bin1.csv', 9656)\n",
    "dfpalm2 = load_and_scale('Palmer_bin2.csv', 115)\n",
    "dfpalm3 = load_and_scale('Palmer_bin3.csv', 7)\n",
    "dfhoust1 = load_and_scale('Houston_bin1.csv', 503)\n",
    "dfhoust2 = load_and_scale('Houston_bin2.csv', 87)\n",
    "dfhoust3 = load_and_scale('Houston_bin3.csv', 7)\n",
    "dfanc_bin1 = load_and_scale('ANC_bin1.csv', 14134)\n",
    "dfanc_bin2 = load_and_scale('ANC_bin2.csv', 472)\n",
    "dfanc_bin3 = load_and_scale('ANC_bin3.csv', 48)\n",
    "dfden_bin1 = load_and_scale('Denali_bin1.csv', 2401)\n",
    "dfden_bin2 = load_and_scale('Denali_bin2.csv', 2)\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "dfBin3 = pd.DataFrame()\n",
    "dfBin3['timestamp'] = dffnsbbin1['timestamp']\n",
    "dfBin3['Total_HP_kWh_b3'] = (\n",
    "    dffnsbbin1['HP_kWh'] + dffnsbbin2['HP_kWh'] + dffnsbbin3['HP_kWh'] +\n",
    "    dfmatbin1['HP_kWh'] + dfmatbin2['HP_kWh'] + dfmatbin3['HP_kWh'] +\n",
    "    dfkenbin1['HP_kWh'] + dfkenbin2['HP_kWh'] + dfkenbin3['HP_kWh'] +\n",
    "    dfancbin1['HP_kWh'] + dfancbin2['HP_kWh'] + dfancbin3['HP_kWh'] +\n",
    "    dfdenbin1['HP_kWh'] + dfdenbin2['HP_kWh']\n",
    ")\n",
    "\n",
    "# Merge and average for each set of Salcha, Fairbanks, and North Pole\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "dfken = merge_dataframes([dfken1, dfken2, dfken3])\n",
    "dfwas = merge_dataframes([dfwas1, dfwas2, dfwas3])\n",
    "dfpalm = merge_dataframes([dfpalm1, dfpalm2, dfpalm3])\n",
    "dfsold = merge_dataframes([dfsold1, dfsold2, dfsold3])\n",
    "dfhoust = merge_dataframes([dfhoust1, dfhoust2, dfhoust3])\n",
    "dfnik = merge_dataframes([dfnik1, dfnik2, dfnik3])\n",
    "dfanc = merge_dataframes([dfanc_bin1, dfanc_bin2, dfanc_bin3])\n",
    "dfden = merge_dataframes([dfden_bin1, dfden_bin2])\n",
    "\n",
    "\n",
    "# Combining averages\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = (\n",
    "    dfsal.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dffbk.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnp.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfken.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfwas.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfpalm.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnik.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfhoust.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfsold.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfanc.filter(like='HP_kWh').sum(axis=1) + \n",
    "    dfden.filter(like='HP_kWh').sum(axis=1)\n",
    ")\n",
    "\n",
    "# Merging FNSB total with combined averages\n",
    "merged_df = pd.merge(dfBin3[['timestamp', 'Total_HP_kWh_b3']], dfc3, on='timestamp')\n",
    "merged_df['variance'] = (merged_df['Total_HP_kWh_b3'] - merged_df['Total_HP_kWh']).abs()\n",
    "merged_df['percent_difference'] = merged_df['variance'] / merged_df[['Total_HP_kWh_b3', 'Total_HP_kWh']].mean(axis=1) * 100\n",
    "\n",
    "# Sorting and selecting top percent differences\n",
    "top_percent_differences = merged_df.sort_values(by='percent_difference', ascending=False).head(5)\n",
    "# Sorting and selecting top variances\n",
    "top_variances = merged_df.sort_values(by='variance', ascending=False).head(5)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 5 percent differences:\")\n",
    "print(top_percent_differences[['timestamp', 'Total_HP_kWh_b3', 'Total_HP_kWh', 'variance', 'percent_difference']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffaa3a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HP_kWh in dfBin3: 30271887619.78201\n",
      "Total HP_kWh in dfc3: 13633021149.963104\n",
      "Variance: 16638866469.818905\n",
      "Percent Difference: 75.80%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and scale data for different bins\n",
    "def load_and_scale(file_path, scale_factor):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['HP_kWh'] *= scale_factor\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp is in datetime format\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "dffnsbbin1 = load_and_scale('FNSB_Bin1.csv', 23016)\n",
    "dffnsbbin2 = load_and_scale('FNSB_Bin2.csv', 1263)\n",
    "dffnsbbin3 = load_and_scale('FNSB_Bin3.csv', 14)\n",
    "dfmatbin1 = load_and_scale('Mat_Su_Bin1.csv', 31691)\n",
    "dfmatbin2 = load_and_scale('Mat_Su_Bin2.csv', 22)\n",
    "dfmatbin3 = load_and_scale('Mat_Su_Bin3.csv', 2)\n",
    "dfkenbin1 = load_and_scale('KPB_Bin1.csv', 3458)\n",
    "dfkenbin2 = load_and_scale('KPB_Bin2.csv', 603)\n",
    "dfkenbin3 = load_and_scale('KPB_Bin3.csv', 18)\n",
    "dfancbin1 = load_and_scale('ANC_Bin1.csv', 14134)\n",
    "dfancbin2 = load_and_scale('ANC_Bin2.csv', 472)\n",
    "dfancbin3 = load_and_scale('ANC_Bin3.csv', 48)\n",
    "dfdenbin1 = load_and_scale('Denali_Bin1.csv', 2401)\n",
    "dfdenbin2 = load_and_scale('Denali_Bin2.csv', 2)\n",
    "\n",
    "dfsal1 = load_and_scale('Salcha_bin1.csv', 275)\n",
    "dfsal2 = load_and_scale('Salcha_bin2.csv', 183)\n",
    "dfsal3 = load_and_scale('Salcha_bin3.csv', 18)\n",
    "dffbk1 = load_and_scale('FBK_bin1.csv', 15840)\n",
    "dffbk2 = load_and_scale('FBK_bin2.csv', 853)\n",
    "dffbk3 = load_and_scale('FBK_bin3.csv', 10)\n",
    "dfnp1 = load_and_scale('NP_bin1.csv', 6329)\n",
    "dfnp2 = load_and_scale('NP_bin2.csv', 778)\n",
    "dfnp3 = load_and_scale('NP_bin3.csv', 7)\n",
    "dfken1 = load_and_scale('Kenai_bin1.csv', 3458)\n",
    "dfken2 = load_and_scale('Kenai_bin2.csv', 603)\n",
    "dfken3 = load_and_scale('Kenai_bin3.csv', 18)\n",
    "dfwas1 = load_and_scale('Wasilla_bin1.csv', 21322)\n",
    "dfwas2 = load_and_scale('Wasilla_bin2.csv', 16)\n",
    "dfwas3 = load_and_scale('Wasilla_bin3.csv', 2)\n",
    "dfnik1 = load_and_scale('Nikiski_bin1.csv', 386)\n",
    "dfnik2 = load_and_scale('Nikiski_bin2.csv', 156)\n",
    "dfnik3 = load_and_scale('Nikiski_bin3.csv', 12)\n",
    "dfsold1 = load_and_scale('Soldotna_bin1.csv', 4653)\n",
    "dfsold2 = load_and_scale('Soldotna_bin2.csv', 437)\n",
    "dfsold3 = load_and_scale('Soldotna_bin3.csv', 9)\n",
    "dfpalm1 = load_and_scale('Palmer_bin1.csv', 9656)\n",
    "dfpalm2 = load_and_scale('Palmer_bin2.csv', 115)\n",
    "dfpalm3 = load_and_scale('Palmer_bin3.csv', 7)\n",
    "dfhoust1 = load_and_scale('Houston_bin1.csv', 503)\n",
    "dfhoust2 = load_and_scale('Houston_bin2.csv', 87)\n",
    "dfhoust3 = load_and_scale('Houston_bin3.csv', 7)\n",
    "dfanc_bin1 = load_and_scale('ANC_bin1.csv', 14134)\n",
    "dfanc_bin2 = load_and_scale('ANC_bin2.csv', 472)\n",
    "dfanc_bin3 = load_and_scale('ANC_bin3.csv', 48)\n",
    "dfden_bin1 = load_and_scale('Denali_bin1.csv', 2401)\n",
    "dfden_bin2 = load_and_scale('Denali_bin2.csv', 2)\n",
    "\n",
    "# Function to merge dataframes without averaging\n",
    "def merge_dataframes(dfs):\n",
    "    df_merged = pd.merge(dfs[0][['timestamp', 'HP_kWh']], dfs[1][['timestamp', 'HP_kWh']], on='timestamp', suffixes=('_1', '_2'))\n",
    "    for i, df in enumerate(dfs[2:], start=3):  # start=3 because we already have _1 and _2\n",
    "        df_merged = pd.merge(df_merged, df[['timestamp', 'HP_kWh']], on='timestamp')\n",
    "        df_merged.rename(columns={'HP_kWh': f'HP_kWh_{i}'}, inplace=True)  # Correctly rename the last merged column\n",
    "    return df_merged\n",
    "\n",
    "# Combine data for dfBin3\n",
    "dfBin3 = pd.DataFrame()\n",
    "dfBin3['timestamp'] = dffnsbbin1['timestamp']\n",
    "dfBin3['Total_HP_kWh_b3'] = (\n",
    "    dffnsbbin1['HP_kWh'] + dffnsbbin2['HP_kWh'] + dffnsbbin3['HP_kWh'] +\n",
    "    dfmatbin1['HP_kWh'] + dfmatbin2['HP_kWh'] + dfmatbin3['HP_kWh'] +\n",
    "    dfkenbin1['HP_kWh'] + dfkenbin2['HP_kWh'] + dfkenbin3['HP_kWh'] +\n",
    "    dfancbin1['HP_kWh'] + dfancbin2['HP_kWh'] + dfancbin3['HP_kWh'] +\n",
    "    dfdenbin1['HP_kWh'] + dfdenbin2['HP_kWh']\n",
    ")\n",
    "\n",
    "# Merge and average for each set of Salcha, Fairbanks, and North Pole\n",
    "dfsal = merge_dataframes([dfsal1, dfsal2, dfsal3])\n",
    "dffbk = merge_dataframes([dffbk1, dffbk2, dffbk3])\n",
    "dfnp = merge_dataframes([dfnp1, dfnp2, dfnp3])\n",
    "dfken = merge_dataframes([dfken1, dfken2, dfken3])\n",
    "dfwas = merge_dataframes([dfwas1, dfwas2, dfwas3])\n",
    "dfpalm = merge_dataframes([dfpalm1, dfpalm2, dfpalm3])\n",
    "dfsold = merge_dataframes([dfsold1, dfsold2, dfsold3])\n",
    "dfhoust = merge_dataframes([dfhoust1, dfhoust2, dfhoust3])\n",
    "dfnik = merge_dataframes([dfnik1, dfnik2, dfnik3])\n",
    "dfanc = merge_dataframes([dfanc_bin1, dfanc_bin2, dfanc_bin3])\n",
    "dfden = merge_dataframes([dfden_bin1, dfden_bin2])\n",
    "\n",
    "# Combining averages for dfc3\n",
    "dfc3 = pd.DataFrame()\n",
    "dfc3['timestamp'] = dfsal['timestamp']\n",
    "dfc3['Total_HP_kWh'] = (\n",
    "    dfsal.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dffbk.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnp.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfken.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfwas.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfpalm.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfnik.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfhoust.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfsold.filter(like='HP_kWh').sum(axis=1) +\n",
    "    dfanc.filter(like='HP_kWh').sum(axis=1) + \n",
    "    dfden.filter(like='HP_kWh').sum(axis=1)\n",
    ")\n",
    "\n",
    "# Calculate total HP_kWh for each DataFrame\n",
    "total_HP_kWh_b3 = dfBin3['Total_HP_kWh_b3'].sum()\n",
    "total_HP_kWh_c3 = dfc3['Total_HP_kWh'].sum()\n",
    "\n",
    "# Calculate the absolute variance and percent difference\n",
    "variance = abs(total_HP_kWh_b3 - total_HP_kWh_c3)\n",
    "percent_difference = (variance / ((total_HP_kWh_b3 + total_HP_kWh_c3) / 2)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total HP_kWh in dfBin3: {total_HP_kWh_b3}\")\n",
    "print(f\"Total HP_kWh in dfc3: {total_HP_kWh_c3}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Percent Difference: {percent_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d94ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
